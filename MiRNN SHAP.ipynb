{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c3beeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import linregress, spearmanr\n",
    "\n",
    "from armored.models import *\n",
    "from armored.preprocessing import *\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import re\n",
    "import itertools\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import shap\n",
    "\n",
    "colors = [\n",
    "    \"#1f77b4\",  # Blue\n",
    "    \"#ff7f0e\",  # Orange\n",
    "    \"#2ca02c\",  # Green\n",
    "    \"#d62728\",  # Red\n",
    "    \"#9467bd\",  # Purple\n",
    "    \"#8c564b\",  # Brown\n",
    "    \"#e377c2\",  # Pink\n",
    "    \"#7f7f7f\",  # Gray\n",
    "    \"#bcbd22\",  # Olive\n",
    "    \"#17becf\",  # Teal\n",
    "    \"#9edae5\",  # Light Blue\n",
    "    \"#c7c7c7\",  # Light Gray\n",
    "    \"#c49c94\",  # Light Red\n",
    "    \"#98df8a\",  # Light Green\n",
    "    \"#f7b6d2\"   # Light Pink\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3285147e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AC_OD', 'BA_OD', 'BC_OD', 'BL_OD', 'BT_OD', 'BV_OD', 'CC_OD',\n",
       "       'DF_OD', 'wt_OD', 'delarc_OD', 'parc-_OD', 'parc+_OD', 'pH'],\n",
       "      dtype='<U32')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import community data\n",
    "df_comm = pd.read_csv(\"Data/arc_allcomm.csv\")\n",
    "\n",
    "# import monoculture data\n",
    "df_mono = pd.read_csv(\"Data/arc_allmono.csv\")\n",
    "\n",
    "# combine data for Fit\n",
    "df = pd.concat((df_comm, df_mono))\n",
    "\n",
    "# define species and pH\n",
    "species = ['AC_OD', 'BA_OD', 'BC_OD', 'BL_OD', 'BT_OD', 'BV_OD', \n",
    "           'CC_OD', 'DF_OD', 'wt_OD', 'delarc_OD', 'parc-_OD', 'parc+_OD']\n",
    "controls = []\n",
    "metabolites = ['pH']\n",
    "\n",
    "# concatenate all observed and all system variables \n",
    "observed = np.concatenate((np.array(species), np.array(metabolites)))\n",
    "system_variables = np.concatenate((np.array(species), np.array(metabolites), np.array(controls)))\n",
    "system_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d7556a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average replicates in train set for fitting data transform\n",
    "df_copy = df.copy()\n",
    "df_copy['Experiments'] = [re.split(r'(_\\d+)', exp_name, maxsplit=1)[0] for exp_name in df_copy.Experiments.values]\n",
    "df_avg = []\n",
    "for exp_name, df_exp in df_copy.groupby(\"Experiments\"):\n",
    "    df_groups = df_exp.groupby(\"Time\")\n",
    "    df_avg_i = df_groups[system_variables].mean().reset_index()\n",
    "    df_avg_i.insert(0, \"Experiments\", [exp_name]*df_avg_i.shape[0])\n",
    "    df_avg.append(df_avg_i)\n",
    "df_avg = pd.concat(df_avg)\n",
    "\n",
    "# scale data \n",
    "# scaler = MinQuantileScaler(observed, system_variables, quantile=.75)\n",
    "scaler = MinMaxScaler(observed, system_variables)\n",
    "\n",
    "scaler.fit(df_avg)\n",
    "df_scaled = scaler.transform(df.copy())\n",
    "df_avg_scaled = scaler.transform(df_avg.copy())\n",
    "\n",
    "# format data into matrix [n_samples, n_timepoints, dt+n_outputs+n_controls]\n",
    "data = format_data(df, species, metabolites, controls, observed=observed)\n",
    "data_avg = format_data(df_avg, species, metabolites, controls, observed=observed)\n",
    "\n",
    "data_scaled = format_data(df_scaled, species, metabolites, controls, observed=observed)\n",
    "data_avg_scaled = format_data(df_avg_scaled, species, metabolites, controls, observed=observed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d14656d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate model\n",
    "brnn = miRNN(n_species=len(species), \n",
    "             n_metabolites=len(metabolites), \n",
    "             n_controls=len(controls), \n",
    "             n_hidden=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1ff8c30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total measurements: 6156, Number of parameters: 717, Initial regularization: 1.00e-03\n",
      "Loss: 1110.632, Residuals: -0.00695\n",
      "Loss: 1051.771, Residuals: -0.02609\n",
      "Loss: 967.924, Residuals: -0.01695\n",
      "Loss: 926.150, Residuals: -0.00036\n",
      "Loss: 901.454, Residuals: -0.00023\n",
      "Loss: 844.330, Residuals: -0.01079\n",
      "Loss: 823.322, Residuals: 0.00133\n",
      "Loss: 680.525, Residuals: 0.00287\n",
      "Loss: 678.264, Residuals: -0.00040\n",
      "Loss: 661.246, Residuals: 0.00074\n",
      "Loss: 631.117, Residuals: 0.00197\n",
      "Loss: 629.958, Residuals: -0.00033\n",
      "Loss: 586.862, Residuals: 0.00133\n",
      "Loss: 584.798, Residuals: -0.00152\n",
      "Loss: 565.582, Residuals: -0.00076\n",
      "Loss: 534.548, Residuals: 0.00109\n",
      "Loss: 522.714, Residuals: 0.00179\n",
      "Loss: 521.163, Residuals: -0.00046\n",
      "Loss: 518.238, Residuals: -0.00042\n",
      "Loss: 513.780, Residuals: -0.00020\n",
      "Loss: 508.634, Residuals: 0.00082\n",
      "Loss: 508.387, Residuals: -0.00009\n",
      "Loss: 499.287, Residuals: 0.00012\n",
      "Loss: 489.160, Residuals: 0.00000\n",
      "Loss: 487.991, Residuals: 0.00048\n",
      "Loss: 481.780, Residuals: 0.00165\n",
      "Loss: 478.813, Residuals: 0.00021\n",
      "Loss: 473.335, Residuals: 0.00029\n",
      "Loss: 472.098, Residuals: 0.00039\n",
      "Loss: 471.869, Residuals: -0.00047\n",
      "Loss: 462.121, Residuals: 0.00106\n",
      "Loss: 461.758, Residuals: -0.00006\n",
      "Loss: 447.632, Residuals: -0.00110\n",
      "Loss: 445.299, Residuals: 0.00009\n",
      "Loss: 440.951, Residuals: 0.00015\n",
      "Loss: 433.872, Residuals: -0.00004\n",
      "Loss: 423.241, Residuals: 0.00000\n",
      "Loss: 404.174, Residuals: -0.00005\n",
      "Loss: 395.532, Residuals: 0.00052\n",
      "Loss: 390.248, Residuals: 0.00002\n",
      "Loss: 386.310, Residuals: 0.00052\n",
      "Loss: 383.272, Residuals: 0.00052\n",
      "Loss: 359.009, Residuals: 0.00003\n",
      "Loss: 348.543, Residuals: 0.00329\n",
      "Loss: 346.739, Residuals: 0.00157\n",
      "Loss: 343.605, Residuals: 0.00113\n",
      "Loss: 339.661, Residuals: 0.00009\n",
      "Loss: 333.074, Residuals: 0.00031\n",
      "Loss: 329.750, Residuals: -0.00052\n",
      "Loss: 328.307, Residuals: 0.00047\n",
      "Loss: 316.500, Residuals: 0.00028\n",
      "Loss: 316.087, Residuals: 0.00054\n",
      "Loss: 302.203, Residuals: 0.00024\n",
      "Loss: 301.881, Residuals: 0.00006\n",
      "Loss: 301.375, Residuals: 0.00001\n",
      "Loss: 296.715, Residuals: -0.00000\n",
      "Loss: 296.483, Residuals: 0.00013\n",
      "Loss: 294.521, Residuals: 0.00010\n",
      "Loss: 290.755, Residuals: 0.00009\n",
      "Loss: 289.701, Residuals: -0.00014\n",
      "Loss: 289.060, Residuals: -0.00009\n",
      "Loss: 288.009, Residuals: -0.00007\n",
      "Loss: 287.730, Residuals: 0.00036\n",
      "Loss: 287.259, Residuals: 0.00019\n",
      "Loss: 273.386, Residuals: 0.00212\n",
      "Loss: 272.107, Residuals: -0.00068\n",
      "Loss: 271.030, Residuals: -0.00021\n",
      "Loss: 269.347, Residuals: -0.00030\n",
      "Loss: 266.159, Residuals: -0.00017\n",
      "Loss: 260.399, Residuals: -0.00000\n",
      "Loss: 260.201, Residuals: -0.00020\n",
      "Loss: 259.773, Residuals: -0.00028\n",
      "Loss: 259.705, Residuals: -0.00015\n",
      "Loss: 259.608, Residuals: -0.00014\n",
      "Loss: 256.228, Residuals: -0.00011\n",
      "Loss: 254.617, Residuals: -0.00020\n",
      "Loss: 253.558, Residuals: -0.00018\n",
      "Loss: 252.865, Residuals: 0.00017\n",
      "Loss: 252.474, Residuals: 0.00002\n",
      "Loss: 248.961, Residuals: 0.00004\n",
      "Loss: 243.313, Residuals: 0.00005\n",
      "Loss: 242.155, Residuals: 0.00015\n",
      "Loss: 241.877, Residuals: -0.00056\n",
      "Loss: 241.355, Residuals: -0.00054\n",
      "Loss: 241.312, Residuals: 0.00009\n",
      "Loss: 240.945, Residuals: 0.00003\n",
      "Loss: 237.630, Residuals: -0.00004\n",
      "Loss: 236.958, Residuals: -0.00005\n",
      "Loss: 236.551, Residuals: -0.00032\n",
      "Loss: 236.437, Residuals: -0.00027\n",
      "Loss: 236.271, Residuals: -0.00024\n",
      "Loss: 236.141, Residuals: -0.00019\n",
      "Loss: 235.893, Residuals: -0.00019\n",
      "Loss: 235.472, Residuals: -0.00018\n",
      "Loss: 234.834, Residuals: -0.00005\n",
      "Loss: 234.459, Residuals: 0.00001\n",
      "Updating precision...\n",
      "adding regularization\n",
      "adding regularization\n",
      "adding regularization\n",
      "adding regularization\n",
      "adding regularization\n",
      "adding regularization\n",
      "adding regularization\n",
      "adding regularization\n",
      "adding regularization\n",
      "adding regularization\n",
      "adding regularization\n",
      "adding regularization\n",
      "adding regularization\n",
      "adding regularization\n",
      "adding regularization\n",
      "adding regularization\n",
      "adding regularization\n",
      "adding regularization\n",
      "Evidence 1625.379\n",
      "Loss: 1380.632, Residuals: 0.00038\n",
      "Loss: 1378.991, Residuals: 0.00039\n",
      "Loss: 1377.493, Residuals: 0.00033\n",
      "Updating precision...\n",
      "Evidence 5891.743\n",
      "Loss: 2533.238, Residuals: 0.00032\n",
      "Updating precision...\n",
      "Evidence 7036.134\n",
      "Loss: 2913.699, Residuals: 0.00010\n",
      "Updating precision...\n",
      "Evidence 7196.302\n",
      "Loss: 3005.224, Residuals: -0.00069\n",
      "Loss: 2999.197, Residuals: -0.00060\n",
      "Loss: 2988.112, Residuals: -0.00052\n",
      "Loss: 2973.872, Residuals: -0.00042\n",
      "Loss: 2953.159, Residuals: -0.00038\n",
      "Loss: 2950.634, Residuals: -0.00069\n",
      "Loss: 2948.974, Residuals: -0.00050\n",
      "Loss: 2945.857, Residuals: -0.00050\n",
      "Loss: 2919.883, Residuals: -0.00040\n",
      "Loss: 2911.863, Residuals: -0.00021\n",
      "Loss: 2892.987, Residuals: -0.00060\n",
      "Loss: 2890.895, Residuals: -0.00053\n",
      "Loss: 2886.696, Residuals: -0.00052\n",
      "Loss: 2882.562, Residuals: -0.00055\n",
      "Loss: 2882.074, Residuals: -0.00054\n",
      "Updating precision...\n",
      "Evidence 7352.982\n",
      "Loss: 2984.748, Residuals: -0.00031\n",
      "Loss: 2983.478, Residuals: -0.00022\n",
      "Updating precision...\n",
      "Evidence 7410.450\n",
      "Loss: 3027.542, Residuals: -0.00029\n",
      "Loss: 3026.340, Residuals: -0.00041\n",
      "Updating precision...\n",
      "Evidence 7440.256\n",
      "Loss: 3028.142, Residuals: -0.00024\n",
      "Loss: 3020.603, Residuals: -0.00068\n",
      "Loss: 3018.079, Residuals: -0.00026\n",
      "Loss: 3003.317, Residuals: -0.00020\n",
      "Loss: 2998.615, Residuals: -0.00047\n",
      "Loss: 2991.847, Residuals: -0.00044\n",
      "Loss: 2980.573, Residuals: -0.00049\n",
      "Loss: 2978.519, Residuals: -0.00046\n",
      "Loss: 2962.454, Residuals: -0.00045\n",
      "Loss: 2962.223, Residuals: -0.00061\n",
      "Loss: 2952.958, Residuals: -0.00062\n",
      "Loss: 2939.538, Residuals: -0.00058\n",
      "Loss: 2939.077, Residuals: -0.00029\n",
      "Loss: 2931.032, Residuals: -0.00022\n",
      "Loss: 2924.088, Residuals: -0.00047\n",
      "Loss: 2922.777, Residuals: -0.00059\n",
      "Loss: 2910.321, Residuals: -0.00059\n",
      "Loss: 2887.918, Residuals: -0.00052\n",
      "Loss: 2887.841, Residuals: -0.00049\n",
      "Updating precision...\n",
      "Evidence 7595.020\n",
      "Loss: 3009.980, Residuals: -0.00020\n",
      "Loss: 3008.443, Residuals: -0.00014\n",
      "Updating precision...\n",
      "Evidence 7641.884\n",
      "Loss: 3047.517, Residuals: -0.00049\n",
      "Loss: 3047.131, Residuals: 0.00027\n",
      "Loss: 3046.597, Residuals: -0.00006\n",
      "Loss: 3045.233, Residuals: -0.00016\n",
      "Loss: 3036.261, Residuals: -0.00019\n",
      "Loss: 3021.126, Residuals: -0.00020\n",
      "Loss: 2998.801, Residuals: -0.00026\n",
      "Loss: 2997.095, Residuals: -0.00054\n",
      "Loss: 2994.463, Residuals: -0.00050\n",
      "Loss: 2989.704, Residuals: -0.00050\n",
      "Loss: 2984.740, Residuals: -0.00043\n",
      "Loss: 2984.071, Residuals: -0.00021\n",
      "Loss: 2983.074, Residuals: -0.00022\n",
      "Loss: 2981.305, Residuals: -0.00021\n",
      "Loss: 2978.081, Residuals: -0.00022\n",
      "Loss: 2974.398, Residuals: -0.00024\n",
      "Loss: 2967.486, Residuals: -0.00024\n",
      "Loss: 2955.713, Residuals: -0.00024\n",
      "Loss: 2954.335, Residuals: -0.00027\n",
      "Loss: 2952.201, Residuals: -0.00021\n",
      "Loss: 2950.848, Residuals: -0.00038\n",
      "Loss: 2949.681, Residuals: -0.00034\n",
      "Loss: 2947.504, Residuals: -0.00035\n",
      "Loss: 2945.133, Residuals: -0.00037\n",
      "Loss: 2940.759, Residuals: -0.00037\n",
      "Loss: 2933.837, Residuals: -0.00036\n",
      "Loss: 2925.008, Residuals: -0.00037\n",
      "Loss: 2916.640, Residuals: -0.00044\n",
      "Loss: 2916.210, Residuals: -0.00041\n",
      "Updating precision...\n",
      "Evidence 7761.278\n",
      "Updating precision...\n",
      "Evidence 7785.384\n",
      "Updating precision...\n",
      "Evidence 7788.109\n",
      "Pass count  1\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "brnn.fit(data_scaled, alpha_0=1e-3, evd_tol=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bae289c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate data points\n",
    "Xs = []\n",
    "all_exp_names = []\n",
    "\n",
    "for (T, X, U, Y, exp_names) in data_scaled:\n",
    "    \n",
    "    all_exp_names.append(exp_names)\n",
    "    for xi, ui in zip(X, U):\n",
    "        \n",
    "        # append design condition\n",
    "        Xs.append(np.append(xi, ui[0]))\n",
    "        \n",
    "# stack \n",
    "X = np.stack(Xs)  \n",
    "all_exp_names = np.concatenate(all_exp_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc893ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all conditions without ecoli\n",
    "no_ecoli_idx = np.sum(X[:, -5:-1], 1) == 0\n",
    "X_no_ecoli = X[no_ecoli_idx]\n",
    "no_ecoli_exp_names = all_exp_names[no_ecoli_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e3aa175",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PermutationExplainer explainer: 203it [00:15,  6.01it/s]                                            \n"
     ]
    }
   ],
   "source": [
    "# species that aren't ecoli\n",
    "not_ecoli = ['AC_OD', 'BA_OD', 'BC_OD', 'BL_OD', 'BT_OD', 'BV_OD', 'CC_OD', 'DF_OD', 'pH']\n",
    "\n",
    "# set of ecoli strains\n",
    "ecoli_strains =  ['wt_OD', 'delarc_OD', 'parc-_OD', 'parc+_OD']\n",
    "\n",
    "# loop over ecoli strains\n",
    "for ecoli_strain in ecoli_strains:\n",
    "\n",
    "    # species + ecoli strain\n",
    "    species_and_strain = not_ecoli + [ecoli_strain]\n",
    "    \n",
    "    # loop over receiver species\n",
    "    for receiver in species_and_strain:\n",
    "        \n",
    "        # index of target species\n",
    "        i = list(system_variables).index(receiver)\n",
    "    \n",
    "        # create wrapper for brnn to match SHAP model \n",
    "        def model(X):\n",
    "\n",
    "            # matrix of predictions over time\n",
    "            U = np.empty(shape=(len(X), 5, 0))\n",
    "            Y = brnn.forward_batch(brnn.params, X, U)\n",
    "\n",
    "            # return endpoint species predictions\n",
    "            return Y[:, -1, i]\n",
    "\n",
    "        # matrix of conditions to explain includes all conditions without ecoli strain\n",
    "        # and all conditions with just the one ecoli strain\n",
    "        ecoli_idx = list(system_variables).index(ecoli_strain)\n",
    "        strain_samples = X[:, ecoli_idx] > 0\n",
    "        X_strain = np.concatenate((X[strain_samples], X_no_ecoli), axis=0)\n",
    "        strain_exp_names = np.append(all_exp_names[strain_samples], no_ecoli_exp_names)\n",
    "        \n",
    "        # compute the SHAP values for the model\n",
    "        explainer = shap.Explainer(model, X_strain)\n",
    "        shap_values = explainer(X_strain)\n",
    "\n",
    "        # init df to save shap values\n",
    "        df_sensitivity = pd.DataFrame()\n",
    "        df_sensitivity[\"Experiments\"] = strain_exp_names\n",
    "        \n",
    "        # loop over affector species\n",
    "        for j, affector in enumerate(system_variables):\n",
    "            \n",
    "            # only care about current ecoli strain\n",
    "            if affector in species_and_strain:\n",
    "                \n",
    "                # name of interaction edge\n",
    "                interaction_name = receiver + \"<--\" + affector\n",
    "\n",
    "                # add shap values\n",
    "                df_sensitivity[interaction_name] = shap_values.values[:, j]\n",
    "\n",
    "        # add exp conditions\n",
    "        for j, affector in enumerate(system_variables):\n",
    "            df_sensitivity[affector] = X_strain[:, j]\n",
    "\n",
    "        # save df \n",
    "        df_sensitivity.to_csv(f\"insights/{ecoli_strain}/{receiver}_shap.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
